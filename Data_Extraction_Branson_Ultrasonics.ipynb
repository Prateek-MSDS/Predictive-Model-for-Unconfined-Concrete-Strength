{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJKGb9_m3QTv"
      },
      "source": [
        "# **Table names used:**\n",
        "\n",
        "\n",
        "**first_table**  :   SpecimenFieldReport.\n",
        "\n",
        "**second_table**  :   SpecimenCompressionTestResult\n",
        "\n",
        "**log_file**  :  Log table to store the invalid files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZkxFJu5KrhJo"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "buOTLc_-MAos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d63055-b9e9-43cf-d65b-aedd16c6f079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4u3c_25hMsHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7388b2-19fb-4a28-96fd-11597dc980e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.6/143.6 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (2022.6.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting camelot-py[base]\n",
            "  Downloading camelot_py-0.11.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from camelot-py[base]) (1.22.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from camelot-py[base]) (0.8.10)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.8/dist-packages (from camelot-py[base]) (1.3.5)\n",
            "Requirement already satisfied: click>=6.7 in /usr/local/lib/python3.8/dist-packages (from camelot-py[base]) (8.1.3)\n",
            "Requirement already satisfied: pdfminer.six>=20200726 in /usr/local/lib/python3.8/dist-packages (from camelot-py[base]) (20221105)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.8/dist-packages (from camelot-py[base]) (4.0.0)\n",
            "Collecting pypdf>=3.0.0\n",
            "  Downloading pypdf-3.5.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.0/244.0 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=2.5.8 in /usr/local/lib/python3.8/dist-packages (from camelot-py[base]) (3.0.10)\n",
            "Collecting pdftopng>=0.2.3\n",
            "  Downloading pdftopng-0.2.3-cp38-cp38-manylinux2010_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3.4.2.17 in /usr/local/lib/python3.8/dist-packages (from camelot-py[base]) (4.6.0.66)\n",
            "Collecting ghostscript>=0.7\n",
            "  Downloading ghostscript-0.7-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: setuptools>=38.6.0 in /usr/local/lib/python3.8/dist-packages (from ghostscript>=0.7->camelot-py[base]) (57.4.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=2.5.8->camelot-py[base]) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23.4->camelot-py[base]) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23.4->camelot-py[base]) (2.8.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six>=20200726->camelot-py[base]) (39.0.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six>=20200726->camelot-py[base]) (3.0.1)\n",
            "Requirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from pypdf>=3.0.0->camelot-py[base]) (4.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py[base]) (1.15.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.4->camelot-py[base]) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py[base]) (2.21)\n",
            "Installing collected packages: pypdf, pdftopng, ghostscript, camelot-py\n",
            "Successfully installed camelot-py-0.11.0 ghostscript-0.7 pdftopng-0.2.3 pypdf-3.5.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 libgs9 libgs9-common\n",
            "  libidn11 libijs-0.35 libjbig2dec0 poppler-data\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf fonts-texgyre\n",
            "  ghostscript-x poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho\n",
            "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n",
            "  fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript libgs9\n",
            "  libgs9-common libidn11 libijs-0.35 libjbig2dec0 poppler-data\n",
            "0 upgraded, 10 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 12.7 MB of archives.\n",
            "After this operation, 51.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 poppler-data all 0.4.9-2 [1,475 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 fonts-noto-mono all 20200323-1build1~ubuntu20.04.1 [80.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-urw-base35 all 20170801.1-3 [6,333 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgs9-common all 9.50~dfsg-5ubuntu4.6 [681 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libidn11 amd64 1.33-2.2ubuntu2 [46.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libijs-0.35 amd64 0.35-15 [15.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 libjbig2dec0 amd64 0.18-1ubuntu1 [60.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgs9 amd64 9.50~dfsg-5ubuntu4.6 [2,173 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 ghostscript amd64 9.50~dfsg-5ubuntu4.6 [51.8 kB]\n",
            "Fetched 12.7 MB in 1s (25.2 MB/s)\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 128221 files and directories currently installed.)\n",
            "Preparing to unpack .../0-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../1-poppler-data_0.4.9-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.9-2) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../2-fonts-noto-mono_20200323-1build1~ubuntu20.04.1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20200323-1build1~ubuntu20.04.1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../3-fonts-urw-base35_20170801.1-3_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20170801.1-3) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../4-libgs9-common_9.50~dfsg-5ubuntu4.6_all.deb ...\n",
            "Unpacking libgs9-common (9.50~dfsg-5ubuntu4.6) ...\n",
            "Selecting previously unselected package libidn11:amd64.\n",
            "Preparing to unpack .../5-libidn11_1.33-2.2ubuntu2_amd64.deb ...\n",
            "Unpacking libidn11:amd64 (1.33-2.2ubuntu2) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../6-libijs-0.35_0.35-15_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../7-libjbig2dec0_0.18-1ubuntu1_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.18-1ubuntu1) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../8-libgs9_9.50~dfsg-5ubuntu4.6_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.50~dfsg-5ubuntu4.6) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../9-ghostscript_9.50~dfsg-5ubuntu4.6_amd64.deb ...\n",
            "Unpacking ghostscript (9.50~dfsg-5ubuntu4.6) ...\n",
            "Setting up fonts-noto-mono (20200323-1build1~ubuntu20.04.1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15) ...\n",
            "Setting up fonts-urw-base35 (20170801.1-3) ...\n",
            "Setting up poppler-data (0.4.9-2) ...\n",
            "Setting up libjbig2dec0:amd64 (0.18-1ubuntu1) ...\n",
            "Setting up libidn11:amd64 (1.33-2.2ubuntu2) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libgs9-common (9.50~dfsg-5ubuntu4.6) ...\n",
            "Setting up libgs9:amd64 (9.50~dfsg-5ubuntu4.6) ...\n",
            "Setting up ghostscript (9.50~dfsg-5ubuntu4.6) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "\u001b[33mWARNING: Skipping PyPDF2 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2<3.0\n",
            "  Downloading pypdf2-2.12.1-py3-none-any.whl (222 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.8/222.8 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from PyPDF2<3.0) (4.5.0)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-2.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber -q\n",
        "!pip install regex\n",
        "!pip install camelot-py[base]\n",
        "!apt-get install ghostscript\n",
        "!pip uninstall -y 'PyPDF2>=3.0'\n",
        "!pip install 'PyPDF2<3.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-1X7D7MxMvwC"
      },
      "outputs": [],
      "source": [
        "import regex as re\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import camelot as cam\n",
        "import pandas as pd\n",
        "from numpy.core.fromnumeric import transpose\n",
        "from pathlib import Path\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLusI4Qe8B3q"
      },
      "source": [
        "# ***SCRAPING DATA INTO FIRST TABLE***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDcEShG3NNhQ"
      },
      "source": [
        "**Function to extract the data into First table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nL1rN-z7NMlX"
      },
      "outputs": [],
      "source": [
        "def extract_first_table(path, text):\n",
        "\n",
        "  global log_file\n",
        "\n",
        "  \n",
        "  Project_Name = Mix_id = City = Date_casted = Date_Report_Issued = Weather = Temperature_Ambient = concrete_supplier = ''\n",
        "  Req_load = Location = Structural_Element = Mix_id = Building_Height = Water_Added = Admixtures_noted = specimen_size = ''\n",
        "\n",
        "\n",
        "  # Fetching the file name\n",
        "  File_name = Path(path).stem\n",
        "\n",
        "\n",
        "  for row in text.split('\\n'):\n",
        "    \n",
        "    #City\n",
        "    if Project_Name == '':\n",
        "      x_proj = re.search(\"Proj\", row)\n",
        "      \n",
        "      if x_proj:\n",
        "        string_proj = row.replace(\" \", \"\")   #print(string_proj)\n",
        "        start = ','\n",
        "        end = ','\n",
        "        City = (string_proj.split(start))[1].split(end)[0]\n",
        "\n",
        "        #Project Name                                                                    # Can it be made a default value?\n",
        "        start = 'Project:'\n",
        "        end = '–'\n",
        "        p_name = (string_proj.split(start))[1].split(end)[0]\n",
        "        Project_Name = p_name.replace('x', ' x ')\n",
        "\n",
        "      else:\n",
        "        City = Project_Name = np.nan\n",
        "\n",
        "\n",
        "    #Date & Cylinder Pick-up Date:\n",
        "    if Date_casted == '':\n",
        "      x_d = re.search(\"Date:\", row)\n",
        "      if x_d:\n",
        "        x_pick = re.search(\"Pick-up Date:\", row)\n",
        "        if x_pick:\n",
        "          Cylinder_pick_up_date = row.split(\"Pick-up Date:\",1)[1].strip()\n",
        "        else:\n",
        "          Date_casted = row.split(\"Date:\",1)[1].strip()\n",
        "      else:\n",
        "        Date_casted == ''\n",
        "\n",
        "\n",
        "    #Date Report Issued & Date tested\n",
        "    x_date = re.search(\"Date\", row)\n",
        "    x_D = re.search(\"DATE\", row)\n",
        "    if x_date:\n",
        "      x_rep = re.search(\"Date Report Issued:\", row)\n",
        "      if x_rep:\n",
        "        Date_Report_Issued = row.split(\"Date Report Issued:\",1)[1].strip()\n",
        "  \n",
        "    elif x_D:\n",
        "      Date_Tested = row.split(\"DATE TESTED\",1)[1].strip()\n",
        "\n",
        "\n",
        "    #Weather\n",
        "    if Weather == '':\n",
        "      x_w = re.search(\"Weather\", row)\n",
        "      if x_w:\n",
        "        string_weather = row.replace(\" \", \"\")   #print(string_proj)\n",
        "        start = 'Weather:'\n",
        "        end = 'Air'\n",
        "        Weather = (string_weather.split(start))[1].split(end)[0].strip()\n",
        "      else:\n",
        "        Weather = ''\n",
        "\n",
        "  \n",
        "    #Temperature_Ambient\n",
        "    if Temperature_Ambient == '':\n",
        "      x = re.search(\"Air\", row)\n",
        "      if x:\n",
        "        string_air = row.replace(\" \", \"\")  \n",
        "\n",
        "        AirTemp = re.search(\"AirTemperature:\", string_air)\n",
        "        if AirTemp:\n",
        "          Temperature_Ambient = string_air[AirTemp.end():][:-3]    #else: Temperatures_Ambient = ''\n",
        "      else:\n",
        "        Temperature_Ambient = ''\n",
        "\n",
        "\n",
        "    #Building Height/Number of Floors\n",
        "    if Building_Height == '':\n",
        "      x_bld_ht = re.search(\"Building height\", row)\n",
        "      if x_bld_ht:\n",
        "        Building_Height = \"Building Height is found\"\n",
        "      else:\n",
        "        Building_Height = np.nan\n",
        "\n",
        "\n",
        "    #Structural Element\n",
        "    if Structural_Element == '':\n",
        "      x_str_el = re.search(\"Structural\", row)\n",
        "      if x_str_el:\n",
        "        Structural_Element = \"Structural Element is found\"\n",
        "      else:\n",
        "        Structural_Element = np.nan\n",
        "\n",
        "\n",
        "    #Location of Placement\n",
        "    if Location == '':\n",
        "      x_loc = re.search(\"Locations:\", row)\n",
        "      if x_loc:\n",
        "        Location = row.split(\"Locations:\",1)[1].strip()            \n",
        "      else:\n",
        "        Location = ''\n",
        "\n",
        "    \n",
        "    #Mix ID\n",
        "    if Mix_id == '':\n",
        "      x_mix = re.search(\"Mix\", row)\n",
        "      if x_mix:\n",
        "        string_mix = row.replace(\" \", \"\")\n",
        "        start = 'Mix'\n",
        "        end = '.'\n",
        "        mixid = (string_mix.split(start))[1].split(end)[0]\n",
        "        Mix_id = re.sub('\\D', '', mixid)\n",
        "      else:\n",
        "        Mix_id = ''\n",
        "\n",
        "\n",
        "    #Water Added\n",
        "    if Water_Added == '':\n",
        "      x_water = re.search(\"Water\", row, re.IGNORECASE)\n",
        "      if x_water:\n",
        "        Water_Added = \"Water found\"\n",
        "      else:\n",
        "        Water_Added = ''\n",
        "\n",
        "    \n",
        "    #Any Admixtures noted, \n",
        "    if Admixtures_noted == '': \n",
        "      x_ad_mix = re.search(\"Admix\", row, re.IGNORECASE)\n",
        "\n",
        "      if x_ad_mix:\n",
        "        Admixtures_noted = \"Admixtures noted is found\"\n",
        "      else:\n",
        "        Admixtures_noted = np.nan\n",
        "\n",
        "\n",
        "    #Required Load\n",
        "    if Req_load == '':\n",
        "      x = re.search(\"CLASS\", row)\n",
        "      if x:\n",
        "        string_req_load = row.replace(\" \", \"\")  \n",
        "        start = 'CLASS(PSI)'\n",
        "        end = 'Max/Min'\n",
        "        Req_load = (string_req_load.split(start))[1].split(end)[0].strip()\n",
        "\n",
        "        #Converting PSI to Kgs/sq in)\n",
        "        #Req_load = int(Req_load)\n",
        "        #Req_load = round(Req_load * 0.4535, 2)\n",
        "\n",
        "      else:\n",
        "        Req_load = ''\n",
        "\n",
        "\n",
        "    #Concrete supplier\n",
        "    if concrete_supplier == '':\n",
        "      x = re.search(\"Supplier\", row)\n",
        "      if x:\n",
        "        string_supplier = row.replace(\" \", \"\")  \n",
        "        start = 'ConcreteSupplier:'\n",
        "        end = 'CylinderPick'\n",
        "        concrete_supplier = (string_supplier.split(start))[1].split(end)[0].strip()\n",
        "      else:\n",
        "        concrete_supplier = ''\n",
        "    \n",
        " \n",
        "    #Specimen size\n",
        "    if specimen_size == '':\n",
        "      x = re.search(\"Field Set\", row)\n",
        "  \n",
        "      if x:\n",
        "        string_size = row.replace(\" \", \"\")  \n",
        "        start = 'FieldSet('\n",
        "        end = ')'\n",
        "        size = (string_size.split(start))[1].split(end)[0].strip().replace('\"', \"\")\n",
        "        specimen_size = re.sub(\"[^A-Z0-9]\", \"\", size,0,re.IGNORECASE)\n",
        "      else:\n",
        "        specimen_size = ''\n",
        "\n",
        "\n",
        "\n",
        "  #### IMPORTING FIELDS TO A DATA FRAME ####\n",
        "  Table_1_header = [\"ReportFileName\", \"Project_Name\", \"City\", \"Date_Molded\", \"ReportDateIssued\", \"SiteWeather\", \"SiteTemperature\", \"ConcreteSupplier\", \"BatchRequiredStrength\", \n",
        "                  \"ConcretePlacementLocation\", \"Structural_Element\", \"BatchMixID\", \"Building_Height\", \"BatchWaterAdded\", \"Admixtures_noted\", \"BatchSpecimenSize\" ]\n",
        "\n",
        "  Values = [File_name, Project_Name, City, Date_casted, Date_Report_Issued, Weather, Temperature_Ambient, concrete_supplier, Req_load, \n",
        "         Location, Structural_Element, Mix_id, Building_Height, Water_Added, Admixtures_noted, specimen_size]\n",
        "\n",
        "  new_row_table_1 = pd.DataFrame(Values, Table_1_header).T\n",
        "\n",
        "  \n",
        "\n",
        "  ##############  Concrete Field Inspection and Test Results  ################\n",
        "\n",
        "\n",
        "  all_tables = cam.read_pdf(path, pages = 'all', flavor = 'lattice', copy_text=['h'])\n",
        "\n",
        "  x_table_field = []\n",
        "\n",
        "  invalid_time_log = []\n",
        "\n",
        "\n",
        "  for i in range(all_tables.n):\n",
        "\n",
        "    if 0 < i <= repeated:\n",
        "      \n",
        "      tab = all_tables[i].df\n",
        "\n",
        "      #Drop unwanted columns:\n",
        "      tab_new = tab.drop(labels=[1,2,3], axis=0)  \n",
        "\n",
        "      #Converting the dataframe to string\n",
        "      tab_new = tab_new.astype(str)\n",
        "\n",
        "      # Replacing empty spaces with Null Values\n",
        "      tab_new = tab_new.replace(r'^\\s*$', np.nan, regex=True)\n",
        "\n",
        "      # Dropping the columns with all Null values:\n",
        "      tab_new = tab_new.dropna(axis=1, how='all')\n",
        "\n",
        "      # Transpose\n",
        "      tab_tran = tab_new.T\n",
        "\n",
        "      # Converting first row into header:\n",
        "      headers = tab_tran.iloc[0]\n",
        "      tab_field = pd.DataFrame(tab_tran.values[1:], columns = headers) \n",
        "\n",
        "      tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
        "\n",
        "      # Replacing the names of first column elements to 'Lab_No' and 'Density' fields:\n",
        "      df_Table_2 =  tab_field\n",
        "      df_Table_2 = df_Table_2.rename(columns={'Field Set (4”x8”) #': 'Lab_no'})\n",
        "      df_Table_2 = df_Table_2.rename(columns={'Density (lbs/cu ft)': 'Unit_Weight (lbs/cu ft)'}) \n",
        "\n",
        "\n",
        "\n",
        "      # Chaging the format of 'Time Discharge' and making the values NULL, for invalid time formats\n",
        "      # And storing them in logfiles.\n",
        "      df_Table_2['Time Discharge'] = df_Table_2['Time Discharge'].str.replace('\\D', '', regex=True)     # Removind values other than digits\n",
        "      \n",
        "      for index in range(len(df_Table_2)):\n",
        "\n",
        "        time_dis = df_Table_2.loc[index, 'Time Discharge']\n",
        "        \n",
        "        if len(time_dis) == 4:\n",
        "          time_conv = datetime.strptime(time_dis, '%H%M').time()\n",
        "          t = time_conv.strftime('%H:%M:%S')\n",
        "          t1 = time_conv.strftime('%I:%M %p')\n",
        "          df_Table_2.loc[index,'Time Discharge'] = t1\n",
        "          df_Table_2.loc[index, 'Batch_Time_Molded'] = t\n",
        "\n",
        "        else:\n",
        "          lab_number = df_Table_2.loc[index,'Lab_no']\n",
        "          df_Table_2.loc[index,'Time Discharge'] = ''                                                                                     \n",
        "          df_Table_2.loc[index, 'Batch_Time_Molded'] =''                                                                                  \n",
        "          Comment = 'Passed NULL value for Time molded for the lab no', lab_number, ' due to incorrect time format'\n",
        "          log_file = log_file.append({'File Name' : File_name, 'Comment' : Comment}, ignore_index = True)\n",
        "\n",
        "\n",
        "      # Rnaming the columns\n",
        "      df_Table_2.rename(columns={\"Air Content (%)\": \"BatchAirContent\"}, inplace=True)\n",
        "      df_Table_2.rename(columns={\"Slump (inches)\": \"BatchtSlump\"}, inplace=True)\n",
        "      df_Table_2.rename(columns={\"Unit_Weight (lbs/cu ft)\": \"BatchUnitWeight\"}, inplace=True)\n",
        "      df_Table_2.rename(columns={\"Concrete Temperature (°F)\": \"BatchTemperature\"}, inplace=True)\n",
        "      df_Table_2.rename(columns={\"Time Discharge\": \"Time_Molded\"}, inplace=True)\n",
        "\n",
        "\n",
        "      if i == 1:\n",
        "        x_table_field = df_Table_2\n",
        "      else:\n",
        "        x_table_field = pd.concat([x_table_field, df_Table_2], axis=0, ignore_index=True)\n",
        "\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "\n",
        "  # MERGING BOTH THE TABLES\n",
        "  \n",
        "  tables_merged = pd.concat([new_row_table_1, x_table_field], axis=1)\n",
        "\n",
        "  tables_merged[\"ReportFileName\"] = File_name \n",
        "  tables_merged[\"Project_Name\"] = Project_Name\n",
        "  tables_merged[\"City\"] = City\n",
        "  tables_merged[\"Date_Molded\"] = Date_casted\n",
        "  tables_merged[\"ReportDateIssued\"] = Date_Report_Issued\n",
        "  tables_merged[\"SiteWeather\"] = Weather\n",
        "  tables_merged[\"SiteTemperature\"] = Temperature_Ambient\n",
        "  tables_merged[\"ConcreteSupplier\"] = concrete_supplier\n",
        "  tables_merged[\"BatchRequiredStrength\"] = Req_load\n",
        "  tables_merged[\"ConcretePlacementLocation\"] = Location\n",
        "  tables_merged[\"Structural_Element\"] = Structural_Element\n",
        "  tables_merged[\"BatchMixID\"] = Mix_id\n",
        "  tables_merged[\"Building_Height\"] = Building_Height\n",
        "  tables_merged[\"BatchWaterAdded\"] = Water_Added\n",
        "  tables_merged[\"Admixtures_noted\"] = Admixtures_noted\n",
        "  tables_merged[\"BatchSpecimenSize\"] = specimen_size\n",
        "\n",
        "   \n",
        "  # Changing the date format of 'Date_Casted' field:\n",
        "  dt_cas = datetime.strptime(Date_casted, '%B %d, %Y').date()\n",
        "  new_date_format = dt_cas.strftime('%Y-%m-%d')\n",
        "\n",
        " \n",
        "  # Batch_time_molded field:\n",
        "\n",
        "  for count in range(len(tables_merged)):\n",
        "    \n",
        "    if tables_merged.loc[count, 'Batch_Time_Molded'] != '':\n",
        "      tables_merged.loc[count, 'Batch_Time_Molded'] = new_date_format + ' ' + tables_merged.loc[count, 'Batch_Time_Molded']\n",
        "\n",
        "  first_table = tables_merged\n",
        "\n",
        "\n",
        "  return first_table\n",
        "\n",
        "  return log_file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJNSaG9Ea4cG"
      },
      "source": [
        "# ***SCRAPING DATA INTO SECOND TABLE***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kRll15GqaqX9"
      },
      "outputs": [],
      "source": [
        "def extract_second_table(path, text):\n",
        "\n",
        "\n",
        "    \n",
        "  read_all_tables = cam.read_pdf(path, pages = 'all', flavor = 'lattice', copy_text=['h'])\n",
        "\n",
        "\n",
        "  x_table = []\n",
        "\n",
        "\n",
        "  for i in range(read_all_tables.n):\n",
        "\n",
        "    if i <= repeated:\n",
        "      continue\n",
        "    else:\n",
        "\n",
        "      tab = read_all_tables[i].df\n",
        "\n",
        "      #Converting the dataframe to string\n",
        "      tab = tab.astype(str)\n",
        "\n",
        "      # Replacing empty spaces with Null Values\n",
        "      tab = tab.replace(r'^\\s*$', np.nan, regex=True)\n",
        "\n",
        "      # Dropping the columns with all Null values:\n",
        "      tab = tab.dropna(axis=1, how='all')\n",
        "\n",
        "      #Drop unwanted columns:\n",
        "      tab_new = tab.drop(labels=[2,3,6,8,9,10,11], axis=0)\n",
        "      tab_new_trans = tab_new.T\n",
        "\n",
        "      # Converting first row into header and Changing name of the first header element\n",
        "      headers = tab_new_trans.iloc[0]\n",
        "      tab_final = pd.DataFrame(tab_new_trans.values[1:], columns = headers)\n",
        "      tab_final.columns.values[0:1] =['Lab_No']\n",
        "\n",
        "      # Changing the name of the field and converting the unit:\n",
        "      tab_final = tab_final.rename(columns={'PSI': 'Unit_Load (PSI)'})\n",
        "\n",
        "      #tab_final['Unit_Load (PSI)'] = pd.to_numeric(tab_final['Unit_Load (PSI)'])\n",
        "      #tab_final['Unit_Load (PSI)'] = (tab_final['Unit_Load (PSI)'] * 0.4535).round(decimals=2)\n",
        "      #tab_final = tab_final.rename(columns={'Unit_Load (PSI)': 'Unit_load (kgs/sq in)'})\n",
        "\n",
        "      tab_final = tab_final.rename(columns={'Unit_Load (PSI)': 'Unit_load (lbs/sq in)'})\n",
        "      tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n",
        "\n",
        "      # Dropping the rows with if any Null values:\n",
        "      tab_final = tab_final.dropna()\n",
        "\n",
        "      if i == repeated + 1:\n",
        "        x_table = tab_final                                                  \n",
        "      else:\n",
        "        x_table = pd.concat([x_table, tab_final], axis=0, ignore_index=True)\n",
        "\n",
        "\n",
        "  # Renaming the columns\n",
        "  x_table.rename(columns={\"CYLINDER #\": \"CylinderTestID\"}, inplace=True)\n",
        "  x_table.rename(columns={\"DATE TESTED\": \"SpecimenDateTested\"}, inplace=True)\n",
        "  x_table.rename(columns={\"TEST AT (days)\": \"SpecimentAgeTested\"}, inplace=True)\n",
        "  x_table.rename(columns={\"Unit_load (lbs/sq in)\": \"SpecimenMeasuredStrength\"}, inplace=True)\n",
        "\n",
        "  return x_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuLG1JqoNTX9"
      },
      "source": [
        "**Importing bulk data into the function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_23kdo1NS36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76752468-2cf5-437c-91dd-0ca791d3a118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18104 - 03-05-20 (28) -20200406.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a51ddfd67b14>:235: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
            "<ipython-input-7-0b94e4262352>:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18104 - 03-05-20 (7) - 20200318.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a51ddfd67b14>:235: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
            "<ipython-input-7-0b94e4262352>:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18104 - 07-25-19 (28 day) Concrete Report - 20190904.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a51ddfd67b14>:235: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
            "<ipython-input-7-0b94e4262352>:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18104 - 01-14-20 (7) - 20200128.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a51ddfd67b14>:235: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
            "<ipython-input-7-0b94e4262352>:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "04-13-20 (28)-20200512.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a51ddfd67b14>:235: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
            "<ipython-input-7-0b94e4262352>:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "04-02-20 (7) .pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a51ddfd67b14>:235: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
            "<ipython-input-7-0b94e4262352>:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "04-13-20 (7)-20200421.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a51ddfd67b14>:235: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
            "<ipython-input-7-0b94e4262352>:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18104 - 01-16-20 (7) - 20200128.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a51ddfd67b14>:235: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
            "<ipython-input-7-0b94e4262352>:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18104 - 01-13-20 (28) - 20200211.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a51ddfd67b14>:235: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
            "<ipython-input-7-0b94e4262352>:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18104 - 01-09-20 (28) - 20200211.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a51ddfd67b14>:235: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_field['Field Set (4”x8”) #'] = tab_field['Field Set (4”x8”) #'].str.replace(r'[^\\d.]+', '')\n",
            "<ipython-input-7-0b94e4262352>:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  tab_final['Lab_No'] = tab_final['Lab_No'].str.replace(r'[^\\d.]+', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "04-02-20 (28) -20200501.pdf\n"
          ]
        }
      ],
      "source": [
        "first_table = []\n",
        "log_table = []\n",
        "second_table = []\n",
        "time_format = ''\n",
        "df_log = []\n",
        "log_file = []\n",
        "\n",
        "\n",
        "# Importing the file folder and reading the files.\n",
        "folder_path = '/content/drive/MyDrive/Colab_Notebooks_Main/Capstone/Files_no_issue'\n",
        "\n",
        "\n",
        "# Creating dataframes to store lod files:\n",
        "df_log = pd.DataFrame(columns=['File Name', 'Comment'])\n",
        "log_file = pd.DataFrame(columns=['File Name', 'Comment'])                 \n",
        "\n",
        "\n",
        "\n",
        "for file in os.listdir(folder_path):\n",
        "  if file.endswith(\".pdf\"):\n",
        "    print(file)\n",
        "\n",
        "\n",
        "    # Skipping the files with age days other than 7 or 28 days,  and maintaining them in Log table\n",
        "    res = re.findall(r'\\(.*?\\)', file)\n",
        "    if not '7' in str(res):\n",
        "      if not '28' in str(res):\n",
        "\n",
        "        df_log = df_log.append({'File Name' : file, 'Comment' : 'Invalid file with Age days other than 7 or 28'}, ignore_index = True)\n",
        "\n",
        "        continue\n",
        "\n",
        "    path = folder_path + '/' + file\n",
        "\n",
        "    pdf = pdfplumber.open(path)\n",
        "    page = pdf.pages[0]\n",
        "    text = page.extract_text()\n",
        "\n",
        "\n",
        "\n",
        "    # Cheking the number of times the string 'Field Set' is repeated, to count the number of 'Concrete Field Inspection and Test Results' tables:\n",
        "    repeated = text.count(\"Field Set\")\n",
        "\n",
        "\n",
        "    # Importing data to the functions\n",
        "\n",
        "    extracted_first = extract_first_table(path, text)\n",
        "\n",
        "    extracted_second = extract_second_table(path, text)\n",
        "\n",
        "\n",
        "\n",
        "    # Appending data into tables:\n",
        "\n",
        "    first_table = extracted_first.append(first_table, ignore_index=True)\n",
        "\n",
        "    second_table = extracted_second.append(second_table, ignore_index=True)\n",
        "\n",
        "    log_file = pd.concat([log_file, df_log], axis=0, ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "    # Delteing duplicate entries from first_table (SpecimenFieldReport) with same Date_Molded and Lab_no\n",
        "    new_first_table = first_table.drop_duplicates(subset = ['Date_Molded', 'Lab_no', 'Time_Molded']).reset_index(drop = True)  \n",
        "\n",
        "    # Delteing duplicate entries from second_table (SpecimenCompressionTestResult):\n",
        "    new_second_table = second_table.drop_duplicates()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oPBD2IPrqTe"
      },
      "outputs": [],
      "source": [
        "# Calculating the time taken for data scrapping\n",
        "\n",
        "end = time.time()\n",
        "time_taken = end - start\n",
        "print('Code took ' ,end - start, ' seconds.')\n",
        "print('Code took ' ,time_taken/60, ' minutes.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLs28D9ZJ4zS"
      },
      "source": [
        "# ***EXPORTING DATA TO EXCEL:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTafIgXM9wxn"
      },
      "outputs": [],
      "source": [
        "first_table.to_excel(r'C:\\Users\\ramgo\\Desktop\\Extracted data\\first_table.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63sYHKi2jiNP"
      },
      "outputs": [],
      "source": [
        "second_table.to_excel(r'C:\\Users\\ramgo\\Desktop\\Extracted data\\second_table.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE8IYEE-EGhu"
      },
      "outputs": [],
      "source": [
        "log_file.to_excel(r'C:\\Users\\ramgo\\Desktop\\Extracted data\\log_table.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_first_table.to_excel(r'C:\\Users\\ramgo\\Desktop\\Extracted data\\new_first_table.xlsx', index=False)"
      ],
      "metadata": {
        "id": "YlHxydyndeWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_second_table.to_excel(r'C:\\Users\\ramgo\\Desktop\\Extracted data\\new_second_table.xlsx', index=False)"
      ],
      "metadata": {
        "id": "14h_zPfJdeSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}