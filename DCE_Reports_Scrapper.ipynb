{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517bc5dc",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04bce871",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq pypdfium2\n",
    "!pip install -Uqq tabula-py\n",
    "!pip install -Uqq pdfplumber\n",
    "!pip install -Uqq python-dateutil\n",
    "!pip install -Uqq xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc613138",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901d836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pypdfium2 as pdfium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import tabula\n",
    "from tabula.io import read_pdf\n",
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c3784",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d58da5",
   "metadata": {},
   "source": [
    "#### Tera Nova Extract Text Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843ae5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tera Nova Extract Text Fields# This function takes pdf as an input\n",
    "# converts into text\n",
    "# returns the required fields\n",
    "    \n",
    "def TeraNovaText(folder,file,prjct_id,scrpr_id):\n",
    "    pdf_fium = pdfium.PdfDocument(folder+'/'+file) # Read the PDF as a text File\n",
    "    pdf_plumb = pdfplumber.open(folder+'/'+file) # Read the PDF as a text File\n",
    "    \n",
    "    no_of_pages = len(pdf_fium)\n",
    "    \n",
    "    out= []\n",
    "    \n",
    "    for i in range(no_of_pages):\n",
    "        temp_out = []\n",
    "        \n",
    "        page_fium = pdf_fium[i] # pdfium\n",
    "        page_plumb = pdf_plumb.pages[i] # PDF Plumber\n",
    "        \n",
    "        # Load a text page helper\n",
    "        textpage_fium = page_fium.get_textpage() # pdfium\n",
    "    \n",
    "        # Extract text from the whole page\n",
    "        text_fium = textpage_fium.get_text_range() # pdfium\n",
    "        text_plumb = page_plumb.extract_text() # PDF Plumber\n",
    "    \n",
    "        # Split the list with the delimiters\n",
    "        list_fium = text_fium.split('\\r\\n') # pdfium\n",
    "        list_plumb = text_plumb.split('\\n')  # PDF Plumber\n",
    "    \n",
    "    \n",
    "        # Store the requird fields\n",
    "    \n",
    "        # Data Ingestion_datetime\n",
    "        Ingestion_datetime = pd.to_datetime('today').strftime(\"%m/%d/%Y %I:%M:%S %p\")\n",
    "    \n",
    "        # City\n",
    "        #City = list_plumb[3].split(',')[0].split(' ')[-1]\n",
    "    \n",
    "        # DATE MOLDED\n",
    "        date_molded_src = \"DATE MOLDED\"\n",
    "        date_molded_src_get_string = [x for x in list_fium if date_molded_src in x]\n",
    "        date_molded_src_lst_str = ''.join(date_molded_src_get_string)\n",
    "        Date_Molded = date_molded_src_lst_str.split(' ')[2]\n",
    "    \n",
    "        # DATE ISSUED\n",
    "        date_issue_src = \"DATE ISSUED\"\n",
    "        date_issue_src_get_string = [x for x in list_fium if date_issue_src in x]\n",
    "        date_issue_src_lst_str = ''.join(date_issue_src_get_string)\n",
    "        Date_Issued = date_issue_src_lst_str.split(':')[1].strip()\n",
    "    \n",
    "        # LAB NUMBER\n",
    "        Lab_Number = date_molded_src_lst_str.split(' ')[5]\n",
    "    \n",
    "        # LOCATION OF PLACEMENT\n",
    "        colon = \":\"\n",
    "        lop_searc = \"LOCATION OF PLACEMENT\"\n",
    "        lop_searc_get_string = [x for x in list_fium if lop_searc in x]\n",
    "        lop_searc_lst_str = ''.join(lop_searc_get_string)\n",
    "\n",
    "        loc = lop_searc_lst_str\n",
    "\n",
    "        if any(c in colon for c in loc):\n",
    "            Location_of_Placement = loc.split(':')[1].strip()\n",
    "        else:\n",
    "            loc = loc.split(' ')\n",
    "            loc.insert(3, ':')\n",
    "            loc = \" \".join(loc) \n",
    "            Location_of_Placement = loc.split(':')[1].strip()\n",
    "        \n",
    "        # CONCRETE SUPPLIER\n",
    "        supplier_src = \"CONCRETE SUPPLIER\"\n",
    "        supplier_src_get_string = [x for x in list_plumb if supplier_src in x]\n",
    "        supplier_src_lst_str = ''.join(supplier_src_get_string)\n",
    "        Concrete_Supplier = supplier_src_lst_str.split('WATER')[0].split(':')[1].strip()\n",
    "        \n",
    "        # MIX ID NO\n",
    "        mixid_src = \"MIX ID NO\"\n",
    "        mixid_src_get_string = [x for x in list_plumb if mixid_src in x]\n",
    "        mixid_src_lst_str = ''.join(mixid_src_get_string)\n",
    "        Mix_ID_No = mixid_src_lst_str.split('UNIT')[0].split(':')[1].strip()\n",
    "    \n",
    "        # WEATHER\n",
    "        weather_src = \"WEATHER\"\n",
    "        weather_src_get_string = [x for x in list_fium if weather_src in x]\n",
    "        if weather_src_get_string:\n",
    "            weather_src_lst_str = ''.join(weather_src_get_string)\n",
    "            Weather = weather_src_lst_str.split(':')[1].strip()\n",
    "            \n",
    "        else:\n",
    "            weather_src = \"W EATHER\"\n",
    "            weather_src_get_string = [x for x in list_fium if weather_src in x]\n",
    "            weather_src_lst_str = ''.join(weather_src_get_string)\n",
    "            Weather = weather_src_lst_str.split(':')[1].strip()\n",
    "    \n",
    "        # TIME MOLDED\n",
    "        time_src = \"TIME MOLDED\"\n",
    "        time_src_get_string = [x for x in list_plumb if time_src in x]\n",
    "        time_src_lst_str = ''.join(time_src_get_string)\n",
    "        Time_Molded = time_src_lst_str.split(' ')[2] + ' ' +time_src_lst_str.split(' ')[3]\n",
    "        if \"ASTM\" in Time_Molded:\n",
    "            Time_Molded = \"\"\n",
    "        else:\n",
    "            Time_Molded = Time_Molded[0:8]\n",
    "    \n",
    "        # AIR CONTENT(%)\n",
    "        aircontent_src = \"AIR CONTENT\"\n",
    "        aircontent_src_get_string = [x for x in list_fium if aircontent_src in x]\n",
    "        aircontent_src_lst_str = ''.join(aircontent_src_get_string)\n",
    "        Air_Content = aircontent_src_lst_str.split(':')[1].strip()\n",
    "        Air_Content = re.sub('[^0-9,.]', '', Air_Content)\n",
    "    \n",
    "        # SLUMP(IN)\n",
    "        slump_src = \"SLUMP(IN)\"\n",
    "        slump_src_get_string = [x for x in list_fium if slump_src in x]\n",
    "        slump_src_lst_str = ''.join(slump_src_get_string)\n",
    "        Slump_space_chck = slump_src_lst_str.split(':')\n",
    "        if len(Slump_space_chck[1])>5:\n",
    "            Slump = Slump_space_chck[1].split(' ')[1].strip()\n",
    "        else:\n",
    "            Slump = Slump_space_chck[1].strip()\n",
    "        \n",
    "        Slump = re.sub('[^0-9,.]', '', Slump)\n",
    "        \n",
    "    \n",
    "        # SIZE & REQUIRED PSI \n",
    "        size_psi_search = \"SIZE:\"\n",
    "        size_psi_get_string = [x for x in list_plumb if size_psi_search in x]\n",
    "        if size_psi_get_string:\n",
    "            size_psi_lst_str = ''.join(size_psi_get_string)\n",
    "            Size = size_psi_lst_str.split('DIAMETER')[0].split(':')[-1].strip()\n",
    "            Required_PSI = size_psi_lst_str.split(' ')[-1].strip()\n",
    "        else:\n",
    "            size_psi_search = \"SIZE\"\n",
    "            size_psi_get_string = [x for x in list_plumb if size_psi_search in x]\n",
    "            size_psi_lst_str = ''.join(size_psi_get_string)\n",
    "            Size = size_psi_lst_str.split('DIAMETER')[0].split('SIZE')[-1].strip()\n",
    "            Required_PSI = size_psi_lst_str.split(' ')[-1].strip()\n",
    "        \n",
    "        # WATER ADDED(GALS)    \n",
    "        water_searc = \"GALS\"\n",
    "        water_searc_get_string = [x for x in list_fium if water_searc in x]\n",
    "        water_searc_lst_str = ''.join(water_searc_get_string)\n",
    "        Water_Added_len_check = water_searc_lst_str.split(':')\n",
    "        \n",
    "        if len(Water_Added_len_check[1])>5:\n",
    "            Water_Added = Water_Added_len_check[1].split(' ')[1].strip()\n",
    "        else:\n",
    "            Water_Added = Water_Added_len_check[1].strip()\n",
    "        \n",
    "        Water_Added = re.sub('[^0-9,.]', '', Water_Added)\n",
    "    \n",
    "    \n",
    "        # UNIT WEIGHT(PCF):\n",
    "        unit_searc = \"PCF\"\n",
    "        unit_searc_get_string = [x for x in list_fium if unit_searc in x]\n",
    "        unit_searc_lst_str = ''.join(unit_searc_get_string)\n",
    "        Unit_Weight = unit_searc_lst_str.split(':')[1].strip()\n",
    "        Unit_Weight = re.sub('[^0-9,.]', '', Unit_Weight)\n",
    "    \n",
    "        # AMBIENT TEMP(F):\n",
    "        ambi_temp_searc = \"AMBIENT TEMP\"\n",
    "        ambi_temp_searc_get_string = [x for x in list_fium if ambi_temp_searc in x]\n",
    "        ambi_temp_searc_lst_str = ''.join(ambi_temp_searc_get_string)\n",
    "        Ambient_Temp = ambi_temp_searc_lst_str.split(':')[1].strip()\n",
    "        Ambient_Temp = re.sub('[^0-9]', '', Ambient_Temp)\n",
    "    \n",
    "        # CONCRETE TEMP(F):\n",
    "        concrete_temp_searc = \"CONCRETE TEMP\"\n",
    "        concrete_temp_searc_get_string = [x for x in list_fium if concrete_temp_searc in x]\n",
    "        concrete_temp_searc_lst_str = ''.join(concrete_temp_searc_get_string)\n",
    "        Concrete_Temp = concrete_temp_searc_lst_str.split(':')[1].strip()\n",
    "        Concrete_Temp = re.sub('[^0-9]', '', Concrete_Temp)\n",
    "        \n",
    "        # PROJECT ID\n",
    "        ProjectID = prjct_id\n",
    "        \n",
    "        # SCRAPER ID\n",
    "        ScraperID = scrpr_id\n",
    "        \n",
    "        temp_out = [ProjectID,ScraperID,file,Ingestion_datetime,Date_Molded,Date_Issued,Lab_Number,Location_of_Placement\n",
    "       ,Concrete_Supplier,Mix_ID_No,Weather,Time_Molded,Air_Content,Slump,Size\n",
    "       ,Required_PSI,Water_Added,Unit_Weight,Ambient_Temp,Concrete_Temp]\n",
    "        \n",
    "        out.append((temp_out))\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29746d4f",
   "metadata": {},
   "source": [
    "#### Tera Nova Extract Test Report Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea56f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes pdf as an input\n",
    "# converts into a dataframe\n",
    "# returns the test results as a DataFrame\n",
    "\n",
    "def TeraNovaPdf2Table(folder,file,result):\n",
    "    readpdf2df = tabula.io.read_pdf(folder+'/'+file \n",
    "                             , pages='all'\n",
    "                             #,output_format=\"dataframe\"\n",
    "                                   , multiple_tables=True)\n",
    "    \n",
    "    df = pd.concat(readpdf2df)\n",
    "    age_load_read = df.iloc[1:,3].dropna().reset_index().drop(columns=['index']).iloc[:-1,]\n",
    "    \n",
    "    drp_extra = age_load_read[age_load_read.iloc[:,0].str.contains('diameter', case=False, na=False)].index\n",
    "    age_load_read = age_load_read.drop(drp_extra)\n",
    "    drp_extra = age_load_read[age_load_read.iloc[:,0].str.contains('compression', case=False, na=False)].index\n",
    "    age_load_read = age_load_read.drop(drp_extra)\n",
    "    drp_extra = age_load_read[age_load_read.iloc[:,0].str.contains('age', case=False, na=False)].index\n",
    "    age_load_read = age_load_read.drop(drp_extra)\n",
    "    \n",
    "    # Extra Space in the Data Check\n",
    "    space_check = age_load_read.iloc[:,0].str.split(' ').tolist()\n",
    "    \n",
    "    space_check_ref = []\n",
    "    for i in space_check:\n",
    "        for j in i:\n",
    "            if len(i)>4:\n",
    "                i[1]=i[1]+i[2]\n",
    "                i.pop(2)\n",
    "        space_check_ref.append(i)\n",
    "    space_check = space_check_ref\n",
    "    age_load_read = pd.DataFrame(space_check, columns =['Age_Days','Date_Tested','Total_load', 'Unit_load'])\n",
    "    final_df = pd.DataFrame()\n",
    "    for i in range(len(result)):\n",
    "        df_split = np.array_split(age_load_read, len(result))\n",
    "        \n",
    "        result_lab = result[i][6]\n",
    "        result_date_isssue = result[i][5]\n",
    "        \n",
    "        df_sel = df_split[i]\n",
    "        \n",
    "        iterat = df_sel.shape[0]\n",
    "        \n",
    "        lab_nbr = pd.DataFrame({'Lab_Number': result_lab}, index=[0])\n",
    "        date_isu = pd.DataFrame({'Date_Issued': result_date_isssue}, index=[0])\n",
    "        \n",
    "        lab_nbr_itr = pd.DataFrame(np.repeat(lab_nbr.values, iterat, axis=0))\n",
    "        date_isu_itr = pd.DataFrame(np.repeat(date_isu.values, iterat, axis=0))\n",
    "        \n",
    "        lab_nbr_itr.columns = lab_nbr.columns\n",
    "        date_isu_itr.columns = date_isu.columns\n",
    "        \n",
    "        temp_df = pd.concat([lab_nbr_itr,date_isu_itr,age_load_read.iloc[:, age_load_read.columns != 'Total_load']], axis=1, join='inner')\n",
    "        final_df = final_df.append(temp_df).reset_index(drop=True)\n",
    "        \n",
    "    \n",
    "    return final_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb08202",
   "metadata": {},
   "source": [
    "#### TeraNova Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26fec7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TeraNova(folder_dir,prjct_id,scrpr_id):\n",
    "    log = []\n",
    "    df_text = []\n",
    "    pdf_df = pd.DataFrame()\n",
    "\n",
    "    #path = '/Users/prateek/Documents/Captsone Project/Jupiter Files/TestFolder'\n",
    "    \n",
    "    #os.chdir('C:/Users/pkakkar/Documents/2023-02-17-DataSet-006-008')\n",
    "    #path = 'C:/Users/pkakkar/Documents/2023-02-17-DataSet-006-008'\n",
    "    \n",
    "    os.chdir(folder_dir)\n",
    "    path = folder_dir\n",
    "\n",
    "\n",
    "    for root, dirs, files in os.walk(path,topdown=True):\n",
    "        if not root.endswith('.DS_Store'):\n",
    "            for file in files:\n",
    "                if file.endswith('.pdf'):\n",
    "                    read_datetime = pd.to_datetime('today').strftime(\"%m/%d/%Y %I:%M:%S %p\")\n",
    "                    folder = os.path.basename(root)\n",
    "                    dir_path = os.path.dirname(root)\n",
    "                \n",
    "                    log.append((prjct_id,scrpr_id,dir_path,folder,file,read_datetime))  # Appends results for log DF\n",
    "                \n",
    "                    result = TeraNovaText(root,file,prjct_id,scrpr_id) # Calls text function\n",
    "                \n",
    "                    for j in range(len(result)):\n",
    "                        df_text.append((result[j]))    # Appends results from text function\n",
    "                     \n",
    "                    df_out = TeraNovaPdf2Table(root,file,result) # Calls Dataframe function\n",
    "                    pdf_df = pdf_df.append(df_out).reset_index(drop=True) # Appends test results DF\n",
    "                \n",
    "\n",
    "    # Append Log DataFrame        \n",
    "    df_log = pd.DataFrame(log, columns=['ProjectID', 'ScraperID','Directory','Folder','File', 'Read_DateTime'])\n",
    "\n",
    "    # Append DataFrame with Text fields\n",
    "    df_page = pd.DataFrame(df_text, columns=['ProjectID',\n",
    "                     'ReportScraperID',\n",
    "                     'File_Name',\n",
    "                     'Ingestion_datetime',\n",
    "                     'Date_Molded',\n",
    "                     'Date_Issued',\n",
    "                     'Lab_Number',\n",
    "                     'Location_of_Placement',\n",
    "                     'Concrete_Supplier',\n",
    "                     'Mix_ID_No',\n",
    "                     'Weather',\n",
    "                     'Time_Molded',\n",
    "                     'Air_Content(%)',\n",
    "                     'Slump(in)',\n",
    "                     'Size',\n",
    "                     'Required_PSI',\n",
    "                     'Water_Added(GALS)',\n",
    "                     'Unit_Weight(PCF)',\n",
    "                     'Ambient_Temp(F)',\n",
    "                     'Concrete_Temp(F)'])\n",
    "    \n",
    "    return df_page,pdf_df,df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec921f3",
   "metadata": {},
   "source": [
    "#### Tera Nova Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28dd433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TeraNovaDataTransform(TeraNovaFieldReport, TeraNovaTestResult):\n",
    "    ############## Create a copy of the Dataframes  #############\n",
    "\n",
    "    TeraNovaFieldReport_stg = TeraNovaFieldReport.copy()\n",
    "    TeraNovaTestResult_stg = TeraNovaTestResult.copy()\n",
    "    \n",
    "    # generate the uuid for BatchLabID \n",
    "    batchlabID = {Lab_Number: str(uuid.uuid4()) for Lab_Number in TeraNovaFieldReport_stg['Lab_Number'].unique()}\n",
    "    \n",
    "    # map uuid\n",
    "    TeraNovaFieldReport_stg['BatchLabID'] = TeraNovaFieldReport_stg['Lab_Number'].map(batchlabID)\n",
    "    \n",
    "    # Add BatchLabID to Results Table\n",
    "    TeraNovaTestResult_stg['BatchLabID'] = TeraNovaTestResult_stg['Lab_Number'].map(batchlabID)\n",
    "    \n",
    "    \n",
    "    ###################### Rename the Columns ########################\n",
    "\n",
    "    TeraNovaFieldReport_stg = TeraNovaFieldReport_stg.rename(columns={'File_Name': 'ReportFileName'\n",
    "                                              , 'Date_Issued': 'ReportDateIssued'\n",
    "                                              , 'Ingestion_datetime': 'ReportTimeIngested'\n",
    "                                              , 'Ambient_Temp(F)': 'SiteTemperature'\n",
    "                                              , 'Weather': 'SiteWeather'\n",
    "                                              , 'Concrete_Supplier': 'ConcreteSupplier'\n",
    "                                              , 'Location_of_Placement': 'ConcretePlacementLocation'\n",
    "                                              , 'Lab_Number': 'BatchLabNumber'\n",
    "                                              , 'Mix_ID_No': 'BatchMixID'\n",
    "                                              , 'Size': 'BatchSpecimenSize'\n",
    "                                              , 'Concrete_Temp(F)': 'BatchTemperature'\n",
    "                                              , 'Unit_Weight(PCF)': 'BatchUnitWeight'\n",
    "                                              , 'Required_PSI': 'BatchRequiredStrength'\n",
    "                                              , 'Air_Content(%)': 'BatchAirContent'\n",
    "                                              , 'Slump(in)': 'BatchtSlump'\n",
    "                                              , 'Water_Added(GALS)': 'BatchWaterAdded'})\n",
    "\n",
    "\n",
    "\n",
    "    TeraNovaTestResult_stg = TeraNovaTestResult_stg.rename(columns={'Lab_Number': 'BatchLabNumber'\n",
    "                                              , 'Date_Issued': 'ReportDateIssued'\n",
    "                                              , 'Date_Tested': 'SpecimenDateTested'\n",
    "                                              , 'Unit_load': 'SpecimenMeasuredStrength'\n",
    "                                              , 'Age_Days': 'SpecimenAgeTested'})\n",
    "\n",
    "\n",
    "\n",
    "    ########### Changing Data Types of Columns for SpecimenFieldReport #########\n",
    "\n",
    "    TeraNovaFieldReport_stg['ReportTimeIngested'] = TeraNovaFieldReport_stg['ReportTimeIngested'].astype('datetime64[ns]')\n",
    "    TeraNovaFieldReport_stg['ReportDateIssued'] = pd.to_datetime(TeraNovaFieldReport_stg[\"ReportDateIssued\"], format=\"%d-%b-%y\")\n",
    "\n",
    "\n",
    "    TeraNovaFieldReport_stg['SiteTemperature'] = TeraNovaFieldReport_stg['SiteTemperature'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    TeraNovaFieldReport_stg['BatchTemperature'] = TeraNovaFieldReport_stg['BatchTemperature'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    TeraNovaFieldReport_stg['BatchUnitWeight'] = TeraNovaFieldReport_stg['BatchUnitWeight'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    TeraNovaFieldReport_stg['BatchRequiredStrength'] = TeraNovaFieldReport_stg['BatchRequiredStrength'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    TeraNovaFieldReport_stg['BatchAirContent'] = TeraNovaFieldReport_stg['BatchAirContent'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    TeraNovaFieldReport_stg['BatchtSlump'] = TeraNovaFieldReport_stg['BatchtSlump'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    TeraNovaFieldReport_stg['BatchWaterAdded'] = TeraNovaFieldReport_stg['BatchWaterAdded'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    #df_page_stg['BatchLabNumber'] = df_page_stg['BatchLabNumber'].astype('int')\n",
    "    TeraNovaFieldReport_stg['SiteTemperature'] = TeraNovaFieldReport_stg['SiteTemperature'].astype('float')\n",
    "    TeraNovaFieldReport_stg['BatchTemperature'] = TeraNovaFieldReport_stg['BatchTemperature'].astype('float')\n",
    "    TeraNovaFieldReport_stg['BatchUnitWeight'] = TeraNovaFieldReport_stg['BatchUnitWeight'].astype('float')\n",
    "    TeraNovaFieldReport_stg['BatchRequiredStrength'] = TeraNovaFieldReport_stg['BatchRequiredStrength'].astype('float')\n",
    "    TeraNovaFieldReport_stg['BatchAirContent'] = TeraNovaFieldReport_stg['BatchAirContent'].astype('float')\n",
    "    TeraNovaFieldReport_stg['BatchtSlump'] = TeraNovaFieldReport_stg['BatchtSlump'].astype('float')\n",
    "    TeraNovaFieldReport_stg['BatchWaterAdded'] = TeraNovaFieldReport_stg['BatchWaterAdded'].astype('float')\n",
    "\n",
    "\n",
    "    TeraNovaFieldReport_stg[\"Time_Molded\"] = TeraNovaFieldReport_stg['Time_Molded'].str.lower()\n",
    "    TeraNovaFieldReport_stg['Time_Molded'] = TeraNovaFieldReport_stg['Time_Molded'].replace({'sm':'am', 'om':'pm'}, regex = True)\n",
    "\n",
    "\n",
    "    TeraNovaFieldReport_stg[\"BatchTimeMolded\"] = TeraNovaFieldReport_stg[\"Date_Molded\"] + ' ' +TeraNovaFieldReport_stg[\"Time_Molded\"]\n",
    "    TeraNovaFieldReport_stg['BatchTimeMolded'] = TeraNovaFieldReport_stg['BatchTimeMolded'].astype('datetime64[ns]')\n",
    "\n",
    "\n",
    "\n",
    "    ########### Changing Data Types of Columns for SpecimenCompressionTestResult #########\n",
    "\n",
    "    # Remove rows with not integer age days\n",
    "    TeraNovaTestResult_stg = TeraNovaTestResult_stg[pd.to_numeric(TeraNovaTestResult_stg['SpecimenAgeTested'], errors='coerce').notna()]\n",
    "\n",
    "    # Change ReportedDateIssues to datetime\n",
    "    TeraNovaTestResult_stg['ReportDateIssued'] = pd.to_datetime(TeraNovaTestResult_stg[\"ReportDateIssued\"], format=\"%d-%b-%y\")\n",
    "\n",
    "    # Create a new dataframe to handle junk datevalue\n",
    "    junk_df = pd.DataFrame()\n",
    "\n",
    "    # This code chnages SpecimenDateTested to datatime format\n",
    "    for i in TeraNovaTestResult_stg['SpecimenDateTested']:\n",
    "        if len(i)!= 9:\n",
    "            junk_df = junk_df.append(TeraNovaTestResult_stg.loc[TeraNovaTestResult_stg['SpecimenDateTested'] == i]).reset_index(drop=True)\n",
    "            TeraNovaTestResult_stg = TeraNovaTestResult_stg.drop(labels=[TeraNovaTestResult_stg.loc[TeraNovaTestResult_stg['SpecimenDateTested'] == i].index.values[0]]\n",
    "                                         , axis=0).reset_index(drop=True)\n",
    "\n",
    "    TeraNovaTestResult_stg['SpecimenDateTested'] = pd.to_datetime(TeraNovaTestResult_stg[\"SpecimenDateTested\"], format=\"%d-%b-%y\")\n",
    "\n",
    "    if junk_df.empty:\n",
    "        pass\n",
    "    else:\n",
    "        junk_df['SpecimenDateTested'] = pd.to_datetime(junk_df[\"SpecimenDateTested\"], format=\"%d-%m-%y\")\n",
    "        TeraNovaTestResult_stg = pd.concat([TeraNovaTestResult_stg, junk_df], ignore_index=True, sort=False)\n",
    "\n",
    "    del junk_df   # Delete Junk dataframe to release memory\n",
    "\n",
    "\n",
    "    # Convert BatchLabNumber to int\n",
    "    #TeraNovaTestResult_stg['BatchLabNumber'] = TeraNovaTestResult_stg['BatchLabNumber'].astype('int')\n",
    "\n",
    "    # Convert SpecimentAgeTest to integer\n",
    "    TeraNovaTestResult_stg['SpecimenAgeTested'] = TeraNovaTestResult_stg['SpecimenAgeTested'].astype('int')\n",
    "\n",
    "\n",
    "    # Remove the outbound rows\n",
    "    TeraNovaTestResult_stg = TeraNovaTestResult_stg[(TeraNovaTestResult_stg['SpecimenAgeTested'] >= 1) & (TeraNovaTestResult_stg['SpecimenAgeTested'] <= age_day_max)]\n",
    "\n",
    "\n",
    "\n",
    "    #################################### Save only the Latest Data ############################################\n",
    "\n",
    "    TeraNovaFieldReport_stg  = TeraNovaFieldReport_stg[TeraNovaFieldReport_stg.groupby('BatchLabNumber')['ReportDateIssued'].transform('max') == TeraNovaFieldReport_stg['ReportDateIssued']].reset_index(drop=True)\n",
    "\n",
    "    TeraNovaTestResult_stg  = TeraNovaTestResult_stg[TeraNovaTestResult_stg.groupby('BatchLabNumber')['ReportDateIssued'].transform('max') == TeraNovaTestResult_stg['ReportDateIssued']].reset_index(drop=True)\n",
    "\n",
    "    # Drop NA values from the compression test report\n",
    "    TeraNovaTestResult_stg = TeraNovaTestResult_stg.dropna()\n",
    "\n",
    "    # Convert SpecimenMeasuredStrength to integer\n",
    "    TeraNovaTestResult_stg['SpecimenMeasuredStrength'] = TeraNovaTestResult_stg['SpecimenMeasuredStrength'].astype('int')\n",
    "\n",
    "    # Add a new column called CylinderTestID\n",
    "    TeraNovaTestResult_stg['CylinderTestID'] = TeraNovaTestResult_stg.sort_values(['ReportDateIssued','SpecimenAgeTested'], ascending=[True,True]) \\\n",
    "                 .groupby(['BatchLabNumber']) \\\n",
    "                 .cumcount() + 1\n",
    "\n",
    "    \n",
    "    return TeraNovaFieldReport_stg,TeraNovaTestResult_stg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe02eb0",
   "metadata": {},
   "source": [
    "#### TeraNova Export Data Files Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb5450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExportDataFiles(TeraNovaFieldReport_Final,TeraNovaTestResult_Final,TeraNovaFileLog,ExportDir):\n",
    "    \n",
    "    os.chdir(ExportDir)\n",
    "    \n",
    "    TeraNovaFieldReport_Final.to_excel('SpecimenFieldReport.xlsx', index=False)\n",
    "    TeraNovaTestResult_Final.to_excel('SpecimenCompressionTestResult.xlsx', index=False)\n",
    "    TeraNovaFileLog.to_excel('INGESTION_LOG.xlsx', index=False)\n",
    "    engineer_report.to_excel('ProjectInformationUpdated.xlsx', index=False)\n",
    "\n",
    "    return 'Excel Files Exported Successfully'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f2979",
   "metadata": {},
   "source": [
    "#### Export Job Log File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e088f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JobLog(TeraNovaFileLog,TeraNovaFieldReport,TeraNovaTestResult,TeraNovaFieldReport_Final,TeraNovaTestResult_Final,jobTimeDiff,ExportDir):\n",
    "    \n",
    "    os.chdir(ExportDir)\n",
    "    \n",
    "    with open('JobComplete.log', 'w') as f:\n",
    "        print('========================================================================================', file=f)\n",
    "        print('\\t\\t\\t\\t',date.today().strftime(\"%A,%d %B, %Y\"), file=f)\n",
    "        print('\\t\\t\\t\\t       ',datetime.now().time().strftime(\"%I:%M:%S %p\"), file=f)\n",
    "        print('========================================================================================', file=f)\n",
    "        print('\\t\\t\\t\\t  TeraNova Scrapper Logs', file=f)\n",
    "        print('========================================================================================', file=f)\n",
    "        print('Total Files Read:', len(TeraNovaFileLog), file=f)\n",
    "        print('Total Reports Read:', len(TeraNovaFieldReport), file=f)\n",
    "        print('Total Test Obervations Read:', len(TeraNovaTestResult), file=f)\n",
    "        print('----------------- Ingestion of Reports with Latest Reporting Date ----------------------', file=f)\n",
    "        print('Total Reports Ingested:', len(TeraNovaFieldReport_Final), file=f)\n",
    "        print('----------------- Ingestion of Acceptable and Latest Test Results ----------------------', file=f)\n",
    "        print('Total Test Results Ingested:', len(TeraNovaTestResult_Final), file=f)\n",
    "        print('========================================================================================', file=f)\n",
    "        print('\\t\\t\\t\\t  Branson Scrapper Logs', file=f)\n",
    "        print('========================================================================================', file=f)\n",
    "        print('Total Files Read:', file=f)\n",
    "        print('Total Reports Read:', file=f)\n",
    "        print('Total Test Obervations Read:', file=f)\n",
    "        print('----------------- Ingestion of Reports with Latest Reporting Date ----------------------', file=f)\n",
    "        print('Total Reports Ingested:', file=f)\n",
    "        print('----------------- Ingestion of Acceptable and Latest Test Results ----------------------', file=f)\n",
    "        print('Total Test Results Ingested:', file=f)\n",
    "        print('========================================================================================', file=f)\n",
    "        print(\"\\t\\t\\tTotal job took %d hours %d minutes %d seconds\" % (jobTimeDiff.hours, jobTimeDiff.minutes, jobTimeDiff.seconds), file=f)\n",
    "        print('========================================================================================', file=f)\n",
    "        \n",
    "    return 'Check JobComplete.log File'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c8361",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe9ea968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert Branson Code\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Check JobComplete.log File'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note Down the Job Start DateTime\n",
    "jobStart = datetime.now()\n",
    "\n",
    "# Save Export Files Directory\n",
    "ExportDir = os.getcwd()\n",
    "\n",
    "# Read the Engineer's File\n",
    "engineer_report = pd.read_excel('ProjectInformation.xlsx')\n",
    "\n",
    "# generate the uuid for ProjectID\n",
    "prjctid = {DCEProjectNumber: str(uuid.uuid4()) for DCEProjectNumber in engineer_report['DCEProjectNumber'].unique()}\n",
    "\n",
    "# map uuid\n",
    "engineer_report['ProjectID'] = engineer_report['DCEProjectNumber'].map(prjctid)\n",
    "\n",
    "# Declare Datframes\n",
    "TeraNovaFieldReport = pd.DataFrame()\n",
    "TeraNovaTestResult = pd.DataFrame()\n",
    "TeraNovaFileLog = pd.DataFrame()\n",
    "TeraNovaFieldReport_Final = pd.DataFrame()\n",
    "TeraNovaTestResult_Final = pd.DataFrame()\n",
    "\n",
    "# Specify a varibale for max age days to consider in the data\n",
    "age_day_max = 100\n",
    "\n",
    "for index, row in engineer_report.iterrows():\n",
    "    if (engineer_report['ScraperID'].isnull()[index]) & (engineer_report['Directory'].isnull()[index]):\n",
    "        pass\n",
    "    else:\n",
    "        scrpr_id = engineer_report['ScraperID'][index]\n",
    "        foldeR_dir = engineer_report['Directory'][index].replace('\\\\', '/')\n",
    "        prjct_id = engineer_report['ProjectID'][index]\n",
    "        \n",
    "        if scrpr_id == 1001:\n",
    "            FieldReport, TestResult, FileLog = TeraNova(foldeR_dir,prjct_id,scrpr_id)\n",
    "            \n",
    "            TeraNovaFieldReport = TeraNovaFieldReport.append(FieldReport).reset_index(drop=True) # Appends results to DF\n",
    "            TeraNovaTestResult = TeraNovaTestResult.append(TestResult).reset_index(drop=True) # Appends results to DF\n",
    "            TeraNovaFileLog = TeraNovaFileLog.append(FileLog).reset_index(drop=True) # Appends results to DF\n",
    "            \n",
    "        elif scrpr_id == 2001:\n",
    "            scrpr_id = engineer_report['ScraperID'][index]\n",
    "            foldeR_dir = engineer_report['Directory'][index].replace('\\\\', '/')\n",
    "            prjct_id = engineer_report['ProjectID'][index]\n",
    "            \n",
    "            print(\"Insert Branson Code\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# Call TeraNova DataTransform Function\n",
    "TeraNovaFieldReport_Final, TeraNovaTestResult_Final = TeraNovaDataTransform(TeraNovaFieldReport, TeraNovaTestResult)\n",
    "\n",
    "# Call Export Data Files Function\n",
    "ExportDataFiles(TeraNovaFieldReport_Final,TeraNovaTestResult_Final,TeraNovaFileLog,ExportDir)\n",
    "\n",
    "# Note Down the Job Finish DateTime\n",
    "jobStop = datetime.now()\n",
    "\n",
    "# Get the JobTime Difference\n",
    "jobTimeDiff = relativedelta(jobStop,jobStart)\n",
    "\n",
    "# Call the Jog Log File Function\n",
    "JobLog(TeraNovaFileLog,TeraNovaFieldReport,TeraNovaTestResult,TeraNovaFieldReport_Final,TeraNovaTestResult_Final,jobTimeDiff,ExportDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2729b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df_page_stg_new['SiteWeather'].values == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b9b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_page_stg_new['SiteTemperature'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb48438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df_page_stg_new['ConcreteSupplier'].values == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b467491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df_page_stg_new['BatchMixID'].values == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7176f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df_page_stg_new['Time_Molded'].values == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92014323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df_page_stg_new['BatchSpecimenSize'].values == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f0b7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_page_stg_new['BatchTemperature'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba4a8a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_page_stg_new['BatchUnitWeight'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e7557fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_page_stg_new['BatchRequiredStrength'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34150370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_page_stg_new['BatchAirContent'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e80812fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_page_stg_new['BatchWaterAdded'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49e569dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ProjectID = Unique Identifier\n",
    "#engineer_report['ProjectID'] = [uuid.uuid4() for i in range(len(engineer_report.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9837437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
